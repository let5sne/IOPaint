# IOPaint Docker éƒ¨ç½²æŒ‡å—

æœ¬ç›®å½•åŒ…å« IOPaint çš„ Docker é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒ CPU å’Œ GPU ä¸¤ç§æ¨¡å¼ã€‚

## ğŸ“¦ å¯ç”¨é•œåƒ

### CPU ç‰ˆæœ¬
é€‚ç”¨äºæ²¡æœ‰ NVIDIA GPU çš„ç¯å¢ƒã€‚

### GPU ç‰ˆæœ¬
é€‚ç”¨äºæœ‰ NVIDIA GPU çš„ç¯å¢ƒï¼Œæ€§èƒ½æ›´å¥½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨é¢„æ„å»ºçš„é•œåƒï¼ˆæ¨èï¼‰

**CPU æ¨¡å¼ï¼š**
```bash
docker pull let5sne/iopaint:cpu-latest
docker run -d -p 8080:8080 let5sne/iopaint:cpu-latest
```

**GPU æ¨¡å¼ï¼š**
```bash
docker pull let5sne/iopaint:gpu-latest
docker run --gpus all -d -p 8080:8080 let5sne/iopaint:gpu-latest
```

è®¿é—® `http://localhost:8080` ä½¿ç”¨ IOPaintã€‚

### ä»æºç æ„å»º

**æ„å»ºæ‰€æœ‰é•œåƒï¼š**
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
bash build_docker.sh 1.0.0  # æ›¿æ¢ä¸ºç‰ˆæœ¬å·
```

**æ„å»ºå•ä¸ªé•œåƒï¼š**

CPU ç‰ˆæœ¬ï¼š
```bash
docker build -f docker/CPUDockerfile -t let5sne/iopaint:cpu-latest .
```

GPU ç‰ˆæœ¬ï¼š
```bash
docker build -f docker/GPUDockerfile -t let5sne/iopaint:gpu-latest .
```

## ğŸ”§ è¿è¡Œé…ç½®

### åŸºç¡€è¿è¡Œ

```bash
# CPU æ¨¡å¼
docker run -d -p 8080:8080 let5sne/iopaint:cpu-latest

# GPU æ¨¡å¼ï¼ˆéœ€è¦ nvidia-dockerï¼‰
docker run --gpus all -d -p 8080:8080 let5sne/iopaint:gpu-latest
```

### æŒ‚è½½æ•°æ®ç›®å½•

```bash
docker run -d \
  -p 8080:8080 \
  -v /path/to/input:/app/input \
  -v /path/to/output:/app/output \
  -v /path/to/models:/root/.cache \
  let5sne/iopaint:gpu-latest
```

### è‡ªå®šä¹‰å¯åŠ¨å‚æ•°

```bash
docker run -d -p 8080:8080 let5sne/iopaint:gpu-latest \
  python3 main.py start \
  --model runwayml/stable-diffusion-inpainting \
  --device cuda \
  --port 8080 \
  --host 0.0.0.0
```

### ä½¿ç”¨ä¸åŒæ¨¡å‹

```bash
# ä½¿ç”¨ SD Inpainting æ¨¡å‹
docker run -d -p 8080:8080 let5sne/iopaint:gpu-latest \
  python3 main.py start --model runwayml/stable-diffusion-inpainting --device cuda --port 8080 --host 0.0.0.0

# ä½¿ç”¨ SDXL æ¨¡å‹ï¼ˆä½å†…å­˜æ¨¡å¼ï¼‰
docker run -d -p 8080:8080 let5sne/iopaint:gpu-latest \
  python3 main.py start --model diffusers/stable-diffusion-xl-1.0-inpainting-0.1 --device cuda --low-mem --port 8080 --host 0.0.0.0
```

## ğŸ“Š Docker Compose

åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  iopaint-gpu:
    image: let5sne/iopaint:gpu-latest
    ports:
      - "8080:8080"
    volumes:
      - ./input:/app/input
      - ./output:/app/output
      - ./models:/root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  iopaint-cpu:
    image: let5sne/iopaint:cpu-latest
    ports:
      - "8081:8080"
    volumes:
      - ./input:/app/input
      - ./output:/app/output
      - ./models:/root/.cache
    restart: unless-stopped
```

å¯åŠ¨ï¼š
```bash
# å¯åŠ¨ GPU æœåŠ¡
docker-compose up -d iopaint-gpu

# å¯åŠ¨ CPU æœåŠ¡
docker-compose up -d iopaint-cpu
```

## ğŸ› ï¸ ç¯å¢ƒå˜é‡

| å˜é‡å | è¯´æ˜ | é»˜è®¤å€¼ |
|--------|------|--------|
| `HF_HOME` | HuggingFace æ¨¡å‹ç¼“å­˜ç›®å½• | `/root/.cache` |
| `PYTORCH_CUDA_ALLOC_CONF` | CUDA å†…å­˜åˆ†é…é…ç½® | - |

è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
docker run -d \
  -p 8080:8080 \
  -e HF_HOME=/models \
  -v /path/to/models:/models \
  let5sne/iopaint:gpu-latest
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### CPU ç‰ˆæœ¬
- RAM: è‡³å°‘ 4GB
- ç£ç›˜: è‡³å°‘ 10GB å¯ç”¨ç©ºé—´

### GPU ç‰ˆæœ¬
- NVIDIA GPUï¼ˆæ”¯æŒ CUDAï¼‰
- VRAM: 
  - LaMa æ¨¡å‹: è‡³å°‘ 2GB
  - SD Inpainting: è‡³å°‘ 8GB
  - SDXL: è‡³å°‘ 12GB
- ç£ç›˜: è‡³å°‘ 20GB å¯ç”¨ç©ºé—´
- nvidia-docker æˆ– Docker 19.03+ï¼ˆæ”¯æŒ --gpusï¼‰

## ğŸ” æ•…éšœæ’æŸ¥

### GPU æ— æ³•ä½¿ç”¨

æ£€æŸ¥ nvidia-docker æ˜¯å¦æ­£ç¡®å®‰è£…ï¼š
```bash
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### ç«¯å£å†²çª

ä¿®æ”¹ç«¯å£æ˜ å°„ï¼š
```bash
docker run -d -p 8888:8080 let5sne/iopaint:gpu-latest
```

### æ¨¡å‹ä¸‹è½½æ…¢

ä½¿ç”¨ HuggingFace é•œåƒï¼š
```bash
docker run -d \
  -p 8080:8080 \
  -e HF_ENDPOINT=https://hf-mirror.com \
  let5sne/iopaint:gpu-latest
```

### å†…å­˜ä¸è¶³

å¯¹äº SDXL ç­‰å¤§æ¨¡å‹ï¼Œä½¿ç”¨ä½å†…å­˜æ¨¡å¼ï¼š
```bash
docker run -d -p 8080:8080 let5sne/iopaint:gpu-latest \
  python3 main.py start --model diffusers/stable-diffusion-xl-1.0-inpainting-0.1 --device cuda --low-mem --cpu-offload --port 8080 --host 0.0.0.0
```

## ğŸ“– æ›´å¤šä¿¡æ¯

- é¡¹ç›®ä¸»é¡µï¼šhttps://github.com/let5sne/IOPaint
- æ–‡æ¡£ï¼šæŸ¥çœ‹é¡¹ç›®æ ¹ç›®å½•çš„ README.md
- é—®é¢˜åé¦ˆï¼šhttps://github.com/let5sne/IOPaint/issues

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¸è¦æš´éœ²åˆ°å…¬ç½‘**ï¼šé»˜è®¤é…ç½®ä»…ç”¨äºæœ¬åœ°ä½¿ç”¨
2. **ä½¿ç”¨ä»£ç†**ï¼šå¦‚éœ€å…¬ç½‘è®¿é—®ï¼Œå»ºè®®ä½¿ç”¨ Nginx åå‘ä»£ç†å¹¶é…ç½® HTTPS
3. **é™åˆ¶èµ„æº**ï¼šä½¿ç”¨ Docker èµ„æºé™åˆ¶é¿å…è¿‡åº¦å ç”¨ç³»ç»Ÿèµ„æº

```bash
docker run -d \
  -p 8080:8080 \
  --memory="4g" \
  --cpus="2.0" \
  let5sne/iopaint:cpu-latest
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### Version 1.0.0 (2025-11-28)
- æ›´æ–°ä¸º IOPaint é¡¹ç›®
- ä½¿ç”¨æœ€æ–°ä¾èµ–ç‰ˆæœ¬
- æ”¯æŒ CUDA 12.1
- ä»æºç æ„å»ºè€Œé PyPI å®‰è£…
- æ·»åŠ è¯¦ç»†çš„ä½¿ç”¨æ–‡æ¡£
